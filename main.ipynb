{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from env.game import Bigtwo\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "\n",
    "class Bigtwo156(nn.Module):\n",
    "    def __init__(self, device):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(device)\n",
    "        self.dense1 = nn.Linear(52 + 52 + 52, 256)\n",
    "        self.dense2 = nn.Linear(256, 128)\n",
    "        self.dense3 = nn.Linear(128, 1)\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Agent156:\n",
    "    def __init__(self):\n",
    "        self.histories = []\n",
    "        self.rewards = []\n",
    "        self.model = Bigtwo156(\"cuda:0\")\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "\n",
    "    def act(self, game):\n",
    "        if len(self.histories) < len(self.rewards) + 1:\n",
    "            self.histories.append([])\n",
    "        obs = self.observe(game)\n",
    "        with torch.no_grad():\n",
    "            output = self.model(obs[\"x_batch\"])\n",
    "        action_index = torch.argmax(output, dim=0)[0]\n",
    "        self.histories[-1].append(obs[\"x_batch\"][action_index])\n",
    "        action = game.players[game.player_to_act].legal_actions[action_index]\n",
    "        game.step(action)\n",
    "\n",
    "    def learn(self):\n",
    "        losses = []\n",
    "        for i, history in enumerate(self.histories):\n",
    "            self.optimizer.zero_grad()\n",
    "            x_batch = torch.stack(history)\n",
    "            output = self.model(x_batch.float())\n",
    "            y_batch = torch.ones(x_batch.shape[0], 1).to(\"cuda:0\") * self.rewards[i]\n",
    "            loss = torch.nn.functional.mse_loss(output, y_batch)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach())\n",
    "        self.histories = []\n",
    "        self.rewards = []\n",
    "        return torch.mean(torch.tensor(losses)).cpu().item()\n",
    "\n",
    "    def observe(self, game: Bigtwo):\n",
    "        players = game.players\n",
    "        player_to_act = game.player_to_act\n",
    "        player = players[player_to_act]\n",
    "        legal_actions = player.legal_actions\n",
    "        legal_actions = torch.tensor(np.array([a.code for a in legal_actions])).to(\n",
    "            \"cuda:0\"\n",
    "        )\n",
    "        holding = torch.tensor(player.holding).to(\"cuda:0\")\n",
    "        other_indices = [\n",
    "            (i + player_to_act) % 4\n",
    "            for i in range(4)\n",
    "            if (i + player_to_act) % 4 != player_to_act\n",
    "        ]\n",
    "        others_holding = [players[i].holding for i in other_indices]\n",
    "        others_holding = np.bitwise_or.reduce(others_holding, axis=0)\n",
    "        others_holding = torch.tensor(others_holding).to(\"cuda:0\")\n",
    "        x = torch.cat([holding, others_holding], dim=0)\n",
    "        x_batch = x.repeat(len(legal_actions), 1)\n",
    "        x_batch = torch.cat([x_batch, legal_actions], dim=1).float()\n",
    "        return dict(\n",
    "            x_batch=x_batch,\n",
    "        )\n",
    "\n",
    "\n",
    "class RandomAgent:\n",
    "    def __init__(self):\n",
    "        self.histories = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def act(self, game: Bigtwo):\n",
    "        index = game.np_random.choice(\n",
    "            len(game.players[game.player_to_act].legal_actions)\n",
    "        )\n",
    "        action = game.players[game.player_to_act].legal_actions[index]\n",
    "        game.step(action)\n",
    "\n",
    "    def learn(self):\n",
    "        self.rewards = []\n",
    "        self.histories = []\n",
    "        return 0\n",
    "\n",
    "\n",
    "game = Bigtwo()\n",
    "\n",
    "agents = [\n",
    "    Agent156(),\n",
    "    Agent156(),\n",
    "    Agent156(),\n",
    "    Agent156(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29, 27, 23, 21]\n",
      "[0.8672682046890259, 0.8304236531257629, 0.8398073315620422, 0.7300475239753723]\n",
      "[33, 22, 25, 20]\n",
      "[0.9081538915634155, 0.7182988524436951, 0.7991465926170349, 0.6800662875175476]\n",
      "[32, 36, 20, 12]\n",
      "[0.9330984354019165, 0.9467445611953735, 0.692852258682251, 0.44227370619773865]\n",
      "[27, 26, 35, 12]\n",
      "[0.8586874604225159, 0.8003907799720764, 0.9206987023353577, 0.448481947183609]\n",
      "[22, 19, 47, 12]\n",
      "[0.7223523855209351, 0.6292674541473389, 1.0040183067321777, 0.4561153054237366]\n",
      "[21, 23, 40, 16]\n",
      "[0.7124958634376526, 0.6792768836021423, 0.9506361484527588, 0.5684380531311035]\n",
      "[30, 11, 38, 21]\n",
      "[0.8432789444923401, 0.4355664551258087, 0.8600237369537354, 0.6897258758544922]\n",
      "[32, 14, 35, 19]\n",
      "[0.8644799590110779, 0.5708885788917542, 0.8646455407142639, 0.5962798595428467]\n",
      "[28, 11, 27, 34]\n",
      "[0.8094014525413513, 0.3815540075302124, 0.7870721220970154, 0.8613006472587585]\n",
      "[30, 14, 27, 29]\n",
      "[0.7937235236167908, 0.4971553385257721, 0.7724397778511047, 0.8228410482406616]\n",
      "[39, 7, 18, 36]\n",
      "[0.891730546951294, 0.3221730887889862, 0.601241409778595, 0.8554088473320007]\n",
      "[29, 9, 14, 48]\n",
      "[0.8278078436851501, 0.38893431425094604, 0.47182610630989075, 1.0070818662643433]\n",
      "[47, 10, 14, 29]\n",
      "[0.9563926458358765, 0.39144447445869446, 0.5481770038604736, 0.7655797600746155]\n",
      "[40, 15, 6, 39]\n",
      "[0.8853392004966736, 0.5302161574363708, 0.22237388789653778, 0.9415801167488098]\n",
      "[31, 14, 21, 34]\n",
      "[0.8529984354972839, 0.469011127948761, 0.624046802520752, 0.8745906949043274]\n",
      "[39, 11, 21, 29]\n",
      "[0.9411108493804932, 0.4213138818740845, 0.5900432467460632, 0.756772518157959]\n",
      "[27, 27, 16, 30]\n",
      "[0.7812278270721436, 0.7632015347480774, 0.5376396179199219, 0.7962630391120911]\n",
      "[35, 14, 23, 28]\n",
      "[0.8538452386856079, 0.4809408187866211, 0.6722826957702637, 0.7941670417785645]\n",
      "[35, 11, 21, 33]\n",
      "[0.8444729447364807, 0.3969654440879822, 0.6486387848854065, 0.8479317426681519]\n",
      "[29, 20, 29, 22]\n",
      "[0.7838199138641357, 0.6673421263694763, 0.7738609313964844, 0.6658812165260315]\n",
      "[29, 22, 18, 31]\n",
      "[0.6583921313285828, 0.6744753122329712, 0.5760344862937927, 0.7124947309494019]\n",
      "[27, 20, 29, 24]\n",
      "[0.7091042399406433, 0.6055376529693604, 0.8393368721008301, 0.7015633583068848]\n",
      "[35, 15, 24, 26]\n",
      "[0.8264209628105164, 0.4751908779144287, 0.7108239531517029, 0.7183787822723389]\n",
      "[32, 18, 25, 25]\n",
      "[0.8220540881156921, 0.5691581964492798, 0.6663066148757935, 0.6907726526260376]\n",
      "[33, 19, 24, 24]\n",
      "[0.7368589639663696, 0.5835059285163879, 0.6898190379142761, 0.6957660913467407]\n",
      "[30, 14, 33, 23]\n",
      "[0.6672545671463013, 0.4553781747817993, 0.7861368656158447, 0.5954301357269287]\n",
      "[32, 21, 20, 27]\n",
      "[0.7130197882652283, 0.5899619460105896, 0.6436339020729065, 0.6222613453865051]\n",
      "[24, 22, 39, 15]\n",
      "[0.7162178158760071, 0.6617273688316345, 0.8568575978279114, 0.5513654351234436]\n",
      "[26, 20, 21, 33]\n",
      "[0.7322540283203125, 0.6154806613922119, 0.5546389222145081, 0.7432408928871155]\n",
      "[24, 22, 29, 25]\n",
      "[0.661021888256073, 0.6093619465827942, 0.6497472524642944, 0.571816086769104]\n",
      "[35, 26, 18, 21]\n",
      "[0.8478307127952576, 0.7067975401878357, 0.6098303198814392, 0.6002767086029053]\n",
      "[25, 22, 27, 26]\n",
      "[0.5992477536201477, 0.6182382106781006, 0.7224363088607788, 0.6944782733917236]\n",
      "[30, 13, 27, 30]\n",
      "[0.730498731136322, 0.44266384840011597, 0.7492122650146484, 0.6585469245910645]\n",
      "[29, 17, 27, 27]\n",
      "[0.6871530413627625, 0.4896445870399475, 0.6801632642745972, 0.6108747720718384]\n",
      "[25, 25, 22, 28]\n",
      "[0.6802811622619629, 0.6970692276954651, 0.5648077130317688, 0.7234741449356079]\n",
      "[34, 19, 23, 24]\n",
      "[0.7867439389228821, 0.5518878102302551, 0.610613226890564, 0.6384144425392151]\n",
      "[30, 27, 26, 17]\n",
      "[0.6029118895530701, 0.7363115549087524, 0.7123507857322693, 0.5667381882667542]\n",
      "[33, 19, 20, 28]\n",
      "[0.7048470973968506, 0.5118964314460754, 0.5487084984779358, 0.626110851764679]\n",
      "[33, 14, 18, 35]\n",
      "[0.6355301141738892, 0.44377243518829346, 0.47580674290657043, 0.6521003842353821]\n",
      "[28, 23, 24, 25]\n",
      "[0.7553653120994568, 0.6113053560256958, 0.624242901802063, 0.5679255127906799]\n",
      "[28, 22, 28, 22]\n",
      "[0.6715050339698792, 0.6162465810775757, 0.665024995803833, 0.60834801197052]\n",
      "[20, 32, 24, 24]\n",
      "[0.515509307384491, 0.7394906878471375, 0.5865839123725891, 0.6103441119194031]\n",
      "[24, 24, 26, 26]\n",
      "[0.6950675845146179, 0.6498138308525085, 0.6397892236709595, 0.6623691320419312]\n",
      "[22, 22, 27, 29]\n",
      "[0.5729206204414368, 0.6513476371765137, 0.668189525604248, 0.6764565110206604]\n",
      "[36, 16, 22, 26]\n",
      "[0.763047456741333, 0.5404385924339294, 0.594337522983551, 0.5693336725234985]\n",
      "[25, 22, 19, 34]\n",
      "[0.6894425749778748, 0.6613719463348389, 0.4696590006351471, 0.7114872932434082]\n",
      "[26, 29, 27, 18]\n",
      "[0.7112036943435669, 0.7629703283309937, 0.6279003620147705, 0.4809785783290863]\n",
      "[39, 18, 25, 18]\n",
      "[0.8475539684295654, 0.5636935234069824, 0.663257896900177, 0.5381972789764404]\n",
      "[31, 20, 27, 22]\n",
      "[0.7772878408432007, 0.6000936627388, 0.7068812847137451, 0.5561825037002563]\n",
      "[24, 25, 31, 20]\n",
      "[0.5662217736244202, 0.6135494709014893, 0.6926308274269104, 0.5406359434127808]\n",
      "[29, 25, 27, 19]\n",
      "[0.7015653848648071, 0.681404173374176, 0.5740585327148438, 0.604028046131134]\n",
      "[27, 23, 23, 27]\n",
      "[0.6209946870803833, 0.5750005841255188, 0.5564340949058533, 0.6665579080581665]\n",
      "[24, 25, 28, 23]\n",
      "[0.6114567518234253, 0.640502393245697, 0.6126500964164734, 0.5999720096588135]\n",
      "[28, 25, 24, 23]\n",
      "[0.5933101177215576, 0.6112515926361084, 0.5592452883720398, 0.585832953453064]\n",
      "[28, 18, 33, 21]\n",
      "[0.48027506470680237, 0.4895346462726593, 0.6190071702003479, 0.4712739884853363]\n",
      "[29, 24, 21, 26]\n",
      "[0.6881429553031921, 0.5817419290542603, 0.45703017711639404, 0.6224859952926636]\n",
      "[31, 19, 21, 29]\n",
      "[0.588807225227356, 0.5210875868797302, 0.5565661787986755, 0.658988893032074]\n",
      "[28, 29, 17, 26]\n",
      "[0.6265113949775696, 0.7354862689971924, 0.3954803943634033, 0.6151914000511169]\n",
      "[22, 21, 28, 29]\n",
      "[0.5750420093536377, 0.6140602231025696, 0.5905665755271912, 0.6336643099784851]\n",
      "[29, 19, 25, 27]\n",
      "[0.6150221824645996, 0.5648618340492249, 0.5402737259864807, 0.5655992031097412]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m game\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwinner \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer_to_act\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(agents):\n\u001b[1;32m      9\u001b[0m     agent\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwinner \u001b[38;5;241m==\u001b[39m index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 40\u001b[0m, in \u001b[0;36mAgent156.act\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     38\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobserve(game)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 40\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_batch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m action_index \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistories[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m][action_index])\n",
      "File \u001b[0;32m~/miniconda3/envs/bigtwo-zero/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bigtwo-zero/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mBigtwo156.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense2(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/bigtwo-zero/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/bigtwo-zero/lib/python3.12/site-packages/torch/nn/modules/module.py:1555\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1556\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    winners = [0, 0, 0, 0]\n",
    "    losses = [0, 0, 0, 0]\n",
    "    for i in range(100):\n",
    "        game.reset()\n",
    "        while game.winner == None:\n",
    "            agents[game.player_to_act].act(game)\n",
    "        for index, agent in enumerate(agents):\n",
    "            agent.rewards.append(1 if game.winner == index else -1)\n",
    "        winners[game.winner] += 1\n",
    "\n",
    "    for index, agent in enumerate(agents):\n",
    "        loss = agent.learn()\n",
    "        losses[index] = loss\n",
    "    print(winners)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer saved as checkpoints/bigtwo_model3_20240923_004149.pth\n"
     ]
    }
   ],
   "source": [
    "from utils.checkpoint import checkpoint\n",
    "\n",
    "\n",
    "checkpoint(model1, optimizer1, \"bigtwo_model3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58, 15, 14, 13]\n",
      "[58, 17, 10, 15]\n",
      "[65, 10, 10, 15]\n",
      "[71, 7, 9, 13]\n",
      "[67, 12, 9, 12]\n",
      "[68, 11, 11, 10]\n",
      "[56, 19, 12, 13]\n",
      "[67, 17, 6, 10]\n",
      "[62, 11, 16, 11]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m     game\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwinner \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mplayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer_to_act\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     winners[game\u001b[38;5;241m.\u001b[39mwinner] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(winners)\n",
      "Cell \u001b[0;32mIn[1], line 44\u001b[0m, in \u001b[0;36mAgent156.act\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistories[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m][action_index])\n\u001b[1;32m     43\u001b[0m action \u001b[38;5;241m=\u001b[39m game\u001b[38;5;241m.\u001b[39mplayers[game\u001b[38;5;241m.\u001b[39mplayer_to_act]\u001b[38;5;241m.\u001b[39mlegal_actions[action_index]\n\u001b[0;32m---> 44\u001b[0m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repository/bigtwo-zero/env/game.py:38\u001b[0m, in \u001b[0;36mBigtwo.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     player\u001b[38;5;241m.\u001b[39mlegal_actions\u001b[38;5;241m.\u001b[39mappend(action)\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayers\u001b[38;5;241m.\u001b[39mappend(player)\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: Action):\n\u001b[1;32m     39\u001b[0m     player \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayers[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplayer_to_act]\n\u001b[1;32m     40\u001b[0m     player\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mappend(action\u001b[38;5;241m.\u001b[39mcode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "players = [\n",
    "    agents[0],\n",
    "    RandomAgent(),\n",
    "    RandomAgent(),\n",
    "    RandomAgent(),\n",
    "]\n",
    "\n",
    "for _ in range(100):\n",
    "    winners = [0, 0, 0, 0]\n",
    "    losses = [0, 0, 0, 0]\n",
    "    for i in range(100):\n",
    "        game.reset()\n",
    "        while game.winner == None:\n",
    "            players[game.player_to_act].act(game)\n",
    "        winners[game.winner] += 1\n",
    "    print(winners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigtwo-zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
