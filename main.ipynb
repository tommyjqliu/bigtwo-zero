{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from agents.bigtwo156 import Agent156\n",
    "from agents.bigtwo376 import Agent376\n",
    "from env.game import Bigtwo\n",
    "from agents.random import RandomAgent\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "game = Bigtwo(42)\n",
    "\n",
    "agents = [\n",
    "    Agent376(\"cuda:0\"),\n",
    "    Agent376(\"cuda:0\"),\n",
    "    Agent376(\"cuda:0\"),\n",
    "    Agent376(\"cuda:0\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer saved as checkpoints/bigtwo376-0_20240923_145804.pth\n",
      "Model and optimizer saved as checkpoints/bigtwo156-2_20240923_145804.pth\n",
      "[14, 47, 6, 33]\n",
      "[0.23307029902935028, 0, 0.10406450927257538, 0]\n",
      "[1, 41, 3, 55]\n",
      "[0.024257250130176544, 0, 0.05829351767897606, 0]\n",
      "[4, 44, 3, 49]\n",
      "[0.07122121006250381, 0, 0.05265111103653908, 0]\n",
      "[2, 48, 2, 48]\n",
      "[0.039825569838285446, 0, 0.03980705887079239, 0]\n",
      "[3, 51, 3, 43]\n",
      "[0.0554499477148056, 0, 0.05649690330028534, 0]\n",
      "[3, 49, 2, 46]\n",
      "[0.05597206577658653, 0, 0.038462527096271515, 0]\n",
      "[6, 48, 3, 43]\n",
      "[0.10143838077783585, 0, 0.053155966103076935, 0]\n",
      "[26, 34, 3, 37]\n",
      "[0.34836113452911377, 0, 0.054448094218969345, 0]\n",
      "[18, 43, 1, 38]\n",
      "[0.26274919509887695, 0, 0.02235298417508602, 0]\n",
      "[21, 40, 1, 38]\n",
      "[0.2811417281627655, 0, 0.02144668810069561, 0]\n",
      "[14, 43, 2, 41]\n",
      "[0.2225583791732788, 0, 0.03824325650930405, 0]\n",
      "[31, 46, 0, 23]\n",
      "[0.3765069544315338, 0, 0.00344003620557487, 0]\n",
      "[54, 21, 0, 25]\n",
      "[0.4303903579711914, 0, 0.001586686703376472, 0]\n",
      "[61, 16, 0, 23]\n",
      "[0.4683036506175995, 0, 0.0012264916440472007, 0]\n",
      "[58, 16, 0, 26]\n",
      "[0.4015195071697235, 0, 0.0011032940819859505, 0]\n",
      "[66, 21, 0, 13]\n",
      "[0.3587409257888794, 0, 0.0006841162103228271, 0]\n",
      "[60, 13, 0, 27]\n",
      "[0.4387206733226776, 0, 0.0006044057081453502, 0]\n",
      "[68, 20, 1, 11]\n",
      "[0.36144858598709106, 0, 0.01916845329105854, 0]\n",
      "[68, 17, 0, 15]\n",
      "[0.3378288745880127, 0, 0.0008850073791109025, 0]\n",
      "[71, 13, 1, 15]\n",
      "[0.296164870262146, 0, 0.018651895225048065, 0]\n",
      "[71, 15, 0, 14]\n",
      "[0.3842390775680542, 0, 0.001281631295569241, 0]\n",
      "[75, 13, 0, 12]\n",
      "[0.3022507429122925, 0, 0.0008219470619224012, 0]\n",
      "[69, 13, 0, 18]\n",
      "[0.3487485945224762, 0, 0.0006746355211362243, 0]\n",
      "[79, 11, 0, 10]\n",
      "[0.2673138380050659, 0, 0.0005281083285808563, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m game\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwinner \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplayer_to_act\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, agent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(agents):\n\u001b[1;32m      9\u001b[0m     agent\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m game\u001b[38;5;241m.\u001b[39mwinner \u001b[38;5;241m==\u001b[39m index \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.33\u001b[39m)\n",
      "File \u001b[0;32m~/repository/bigtwo-zero/agents/bigtwo376.py:68\u001b[0m, in \u001b[0;36mAgent376.act\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistories) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistories\u001b[38;5;241m.\u001b[39mappend([])\n\u001b[0;32m---> 68\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     70\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m], obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mz_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/repository/bigtwo-zero/agents/bigtwo376.py:113\u001b[0m, in \u001b[0;36mAgent376.observe\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m    109\u001b[0m others_played \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    110\u001b[0m     np\u001b[38;5;241m.\u001b[39mbitwise_or\u001b[38;5;241m.\u001b[39mreduce(h, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m h \u001b[38;5;28;01melse\u001b[39;00m empty \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m others_played\n\u001b[1;32m    111\u001b[0m ]\n\u001b[1;32m    112\u001b[0m others_played \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(others_played)\n\u001b[0;32m--> 113\u001b[0m others_played \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mothers_played\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([holding, others_holding, others_played], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    116\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;28mlen\u001b[39m(legal_actions), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in range(1000):\n",
    "    winners = [0, 0, 0, 0]\n",
    "    losses = [0, 0, 0, 0]\n",
    "    for i in range(100):\n",
    "        game.reset()\n",
    "        while game.winner == None:\n",
    "            agents[game.player_to_act].act(game)\n",
    "        for index, agent in enumerate(agents):\n",
    "            agent.rewards.append(1 if game.winner == index else -0.33)\n",
    "        winners[game.winner] += 1\n",
    "\n",
    "    for index, agent in enumerate(agents):\n",
    "        loss = agent.learn()\n",
    "        losses[index] = loss\n",
    "\n",
    "    if j % 200 == 0:\n",
    "        for index, agent in enumerate(agents):\n",
    "            agent.save(index)\n",
    "    print(winners)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer saved as checkpoints/bigtwo376-initial_20240923_150604.pth\n"
     ]
    }
   ],
   "source": [
    "agents[0].save('initial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[209, 19, 253, 19]\n",
      "[243, 12, 215, 30]\n",
      "[216, 18, 251, 15]\n",
      "[238, 24, 220, 18]\n",
      "[238, 16, 222, 24]\n"
     ]
    }
   ],
   "source": [
    "from agents.random import RandomAgent\n",
    "\n",
    "\n",
    "players = [\n",
    "    agents[0],\n",
    "    RandomAgent(),\n",
    "    RandomAgent(),\n",
    "    RandomAgent(),\n",
    "]\n",
    "\n",
    "for _ in range(5):\n",
    "    winners = [0, 0, 0, 0]\n",
    "    losses = [0, 0, 0, 0]\n",
    "    for i in range(500):\n",
    "        game.reset()\n",
    "        while game.winner == None:\n",
    "            players[game.player_to_act].act(game)\n",
    "        winners[game.winner] += 1\n",
    "    print(winners)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigtwo-zero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
